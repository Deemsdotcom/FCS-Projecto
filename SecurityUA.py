import streamlit as st
import requests
import random
import time
from datetime import datetime
import openrouteservice
import pandas as pd
from geopy.distance import geodesic
import json
import os
import numpy as np
import folium
from streamlit_folium import st_folium
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import LabelEncoder
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter

##### shelters
@st.cache_data
def load_data():
    # Load 'shelters.json' (filtering out unsuitable ones) and 'metro.json' (adding metro stations).
    combined_shelters = []
    
    # Part 1: Load the big shelters file.
    try:
        with open("shelters.json", "r", encoding="utf-8") as f:
            data = json.load(f)
            if 'features' in data:
                for feature in data['features']:
                    props = feature.get('properties', {})
                    geom = feature.get('geometry', {})
                    
                    if not geom or 'coordinates' not in geom: 
                        continue
                    
                    # We list types to exclude, like open bus stops or nature shelters.
                    bad_data = [
                        # Transport (Glass danger)
                        "public_transport", "taxi", "bus_stop", "platform",
                        
                        # Park/Nature (Open sides, no walls)
                        "picnic_shelter", "gazebo", "lean_to", "weather_shelter", 
                        "rock_shelter", "sun_shelter", "pergola",
                        
                        # Objects/Animals
                        "bicycle_parking", "bicycle_rental", "field_shelter", 
                        "bench", "atm", "waste_disposal", "smoking_shelter"
                    ]
                    
                    s_type = props.get('shelter_type', 'unknown')
                    amenity = props.get('amenity', 'unknown')
                    
                    # THE BOUNCER CHECK:
                    if s_type in bad_data or amenity in bad_data:
                        continue # SKIP IT!
                        
                    combined_shelters.append({
                        "name": props.get('name', 'Unnamed Shelter'),
                        "type": s_type if s_type != "unknown" else amenity,
                        "lat": geom['coordinates'][1],
                        "lon": geom['coordinates'][0]
                    })
    except Exception as e:
        # If file is missing, just print a small warning to the logs, don't crash
        print(f"Warning: shelters.json error: {e}")

    # --- PART 2: Load the Metro File (metro.json) ---
    try:
        with open("metro.json", "r", encoding="utf-8") as f:
            metro_data = json.load(f)
            if 'features' in metro_data:
                for feature in metro_data['features']:
                    props = feature.get('properties', {})
                    geom = feature.get('geometry', {})
                    
                    combined_shelters.append({
                        "name": props.get('name', 'Metro Station'),
                        "type": "metro_station",
                        "lat": geom['coordinates'][1],
                        "lon": geom['coordinates'][0]
                    })
    except Exception as e:
        # It is okay if metro.json is missing
        pass 

    return pd.DataFrame(combined_shelters)

   

# ==========================================
# API Clients
# ==========================================

class AlertsClient:
    # A simple client to talk to the Alerts API.
    # Note: We're keeping the API token right here in the code.
    # It's not usually safe, but it's okay for this specific project.

    # Base URL of the Alerts API
    BASE_URL = "https://api.alerts.in.ua/v1"

    def __init__(self):
        # ------------------------------------------------------------------
        # THIS IS WHERE YOU PUT YOUR REAL API TOKEN
        # Paste your real working token between the quotes below:
        # ------------------------------------------------------------------
        self.api_key = "3b9da58a53b958cab81355b22e3feb9c10593dc4ab2203"
        # ------------------------------------------------------------------

        # Safety check: if token is missing, stop the app with an error
        if not self.api_key or self.api_key.strip() == "":
            st.error("API token is missing in the code.")
            raise ValueError("API token not set in AlertsClient")

    def get_active_alerts(self) -> dict:
        # Get the currently active alerts from the API.
        
        # We need to send the token in the headers.

        # The API requires the token in the Authorization header
        headers = {
            "Authorization": f"Bearer {self.api_key}"
        }

        # Send a GET request to the /alerts/active.json endpoint
        response = requests.get(
            f"{self.BASE_URL}/alerts/active.json",
            headers=headers,
            timeout=10,  # seconds
        )

        # Raise an error if the response status is not 2xx
        response.raise_for_status()

        # Convert the response body to JSON and return it
        return response.json()



def build_alerts_dataframe(alerts_json: dict) -> pd.DataFrame:
    # Turn the API answer into a pandas DataFrame so we can show it easily.
    alerts_list = alerts_json.get("alerts", [])

    if not alerts_list:
        return pd.DataFrame()

    df = pd.DataFrame(alerts_list)

    # Choose and reorder columns if they exist
    preferred_columns = [
        "id",
        "location_title",
        "location_type",
        "alert_type",
        "started_at",
        "finished_at",
        "notes",
    ]
    existing_columns = [c for c in preferred_columns if c in df.columns]
    df = df[existing_columns]

    # Convert timestamps to nicer datetime format if they exist
    for col in ["started_at", "finished_at"]:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col], errors="coerce")

    return df


# Real-Time Region-Specific Alert Notifications (UI toast + optional alarm)
def is_region_under_air_raid(alerts_data: dict, region_name: str) -> bool:
    """
    Returns True if there is an active air_raid alert in the given region.
    """
    alerts = alerts_data.get("alerts", [])
    for a in alerts:
        if (
            a.get("location_title") == region_name
            and a.get("alert_type") == "air_raid"
            and a.get("finished_at") is None
        ):
            return True
    return False


class RoutingClient:
    def __init__(self, api_key="eyJvcmciOiI1YjNjZTM1OTc4NTExMTAwMDFjZjYyNDgiLCJpZCI6Ijg2ZjI2ODQ1Y2JhMzQ1YTJhNmU3MDgwNDM0NjI4NGY5IiwiaCI6Im11cm11cjY0In0="):
        # ---------------------------------------------------------
        # PASTE YOUR KEY FROM SCREENSHOT 1 BELOW
        # Replace "YOUR_LONG_KEY_HERE" with the real "ey..." string
        # ---------------------------------------------------------
        self.api_key = api_key if api_key else "YOUR_LONG_KEY_HERE"
        
        if self.api_key:
            self.client = openrouteservice.Client(key=self.api_key)
        else:
            self.client = None

    def find_quickest_shelter(self, user_lon, user_lat, candidates_df, profile='foot-walking'):
        # Pick the top 5 shelters and ask the Matrix API which one is actually fastest to reach.
        if not self.client or candidates_df.empty:
            # Fallback: If API is down, just return the first one (closest by straight line)
            return candidates_df.iloc[0] 

        # Prepare coords list: [User, Shelter1, Shelter2, Shelter3, Shelter4, Shelter5]
        # Note: ORS requires [Longitude, Latitude]
        locations = [[user_lon, user_lat]]
        for _, row in candidates_df.iterrows():
            locations.append([row['lon'], row['lat']])

        try:
            # Ask Matrix: "How long from Index 0 (User) to everyone else?"
            matrix = self.client.distance_matrix(
                locations=locations,
                profile=profile,
                metrics=['duration'],
                sources=[0]
            )

            # The API returns a list of times: [0, time_to_shelter1, time_to_shelter2...]
            # We skip index 0 (User->User)
            durations = matrix['durations'][0][1:]
            
            # Add these times to a copy of the dataframe
            candidates_df = candidates_df.copy()
            candidates_df['duration_s'] = durations
            
            # Sort by TIME (duration_s), so the fastest one is at the top
            best_shelter = candidates_df.sort_values('duration_s').iloc[0]
            return best_shelter

        except Exception as e:
            # Fallback: return the closest by math if the API fails
            return candidates_df.iloc[0] 

    def get_route(self, start_coords, end_coords, profile='foot-walking'):
        # Get the actual path (turn-by-turn) to show on the map.
        if not self.client:
            return self._get_mock_route(start_coords, end_coords)
        try:
            return self.client.directions(
                coordinates=[start_coords, end_coords],
                profile=profile,
                format='geojson'
            )
        except Exception:
            return self._get_mock_route(start_coords, end_coords)

    def _get_mock_route(self, start, end):
        # Fallback straight line if internet fails
        return {
            "type": "FeatureCollection", 
            "features": [{"type": "Feature", "geometry": {"type": "LineString", "coordinates": [start, end]}}]
        }





class OSMClient:
    OVERPASS_URL = "https://overpass-api.de/api/interpreter"

    def get_nearby_shelters(self, lat, lon, radius=1000):
        # Find shelters near the user (default 1000m radius).
        overpass_query = f"""
        [out:json];
        (
          node["amenity"="shelter"](around:{radius},{lat},{lon});
          way["amenity"="shelter"](around:{radius},{lat},{lon});
          relation["amenity"="shelter"](around:{radius},{lat},{lon});
          node["location"="underground"](around:{radius},{lat},{lon});
        );
        out center;
        """
        try:
            response = requests.get(self.OVERPASS_URL, params={'data': overpass_query})
            response.raise_for_status()
            data = response.json()
            return self._parse_osm_data(data)
        except requests.RequestException as e:
            st.error(f"Error fetching shelters: {e}")
            return []

    def _parse_osm_data(self, data):
        # Convert the raw OpenStreetMap JSON into a nice list of dictionaries.
        shelters = []
        for element in data.get('elements', []):
            lat = element.get('lat') or element.get('center', {}).get('lat')
            lon = element.get('lon') or element.get('center', {}).get('lon')

            if lat and lon:
                shelters.append({
                    "id": element.get('id'),
                    "type": element.get('tags', {}).get('amenity', 'unknown'),
                    "name": element.get('tags', {}).get('name', 'Unnamed Shelter'),
                    "access": element.get('tags', {}).get('access', 'public'),
                    "lat": lat,
                    "lon": lon,
                    "tags": element.get('tags', {})
                })
        return shelters



class NominatimClient:
    BASE_URL = "https://nominatim.openstreetmap.org"
    USER_AGENT = "SafeShelterUkraine/1.0"

    def geocode(self, query):
        # Turn an address (like "Kyiv, Maidan") into coordinates (lat/lon).
        params = {
            "q": query,
            "format": "json",
            "limit": 1
        }
        headers = {"User-Agent": self.USER_AGENT}

        try:
            response = requests.get(f"{self.BASE_URL}/search", params=params, headers=headers)
            response.raise_for_status()
            data = response.json()
            if data:
                return {
                    "lat": float(data[0]['lat']),
                    "lon": float(data[0]['lon']),
                    "display_name": data[0]['display_name']
                }
            return None
        except requests.RequestException as e:
            st.error(f"Geocoding error: {e}")
            return None

    def reverse_geocode(self, lat, lon):
        # Turn coordinates back into an address string.
        params = {
            "lat": lat,
            "lon": lon,
            "format": "json"
        }
        headers = {"User-Agent": self.USER_AGENT}

        try:
            response = requests.get(f"{self.BASE_URL}/reverse", params=params, headers=headers)
            response.raise_for_status()
            data = response.json()
            return data.get('display_name')
        except requests.RequestException as e:
            st.error(f"Reverse geocoding error: {e}")
            return None


# ==========================================
# Data Processing & Storage
# ==========================================

class DataProcessor:
    SHELTER_TYPES = [
        "Basement / Sub-grade Civilian Shelters",
        "Purpose-Built Public Blast Shelters",
        "Hardened Military Bunkers",
        "Deep Underground Shelters",
        "Improvised / Expedient Shelters",
        "Mobile / Deployable Shelters",
        "Hardened Infrastructure (dual-use)"
    ]

    def process_shelters(self, shelters_data, user_lat, user_lon):
        # Clean up the shelter data, figure out how far away they are, and give them a score.
        if not shelters_data:
            return pd.DataFrame()

        df = pd.DataFrame(shelters_data)

        # Calculate distance for each shelter
        df['distance_m'] = df.apply(
            lambda row: geodesic((user_lat, user_lon), (row['lat'], row['lon'])).meters,
            axis=1
        )

        # Classify and Score
        df = df.apply(self._enrich_shelter_data, axis=1)

        # Sort by distance
        df = df.sort_values('distance_m')

        return df

    def _enrich_shelter_data(self, row):
        # Figure out the type and score for just one shelter.
        tags = row.get('tags', {})

        # 1. Classify Type
        row['type'] = self._classify_shelter(tags)

        # 2. Generate Scores (1-10)
        scores = self._generate_scores(row['type'], tags)
        for key, value in scores.items():
            row[key] = value

        # Calculate overall score (simple average)
        row['overall_rating'] = sum(scores.values()) / len(scores)

        return row

    def _classify_shelter(self, tags):
        # Decide which of the 7 types this shelter is, based on its tags.
        # Heuristic mapping
        if tags.get('access') == 'private' or tags.get('military') == 'bunker':
            return "Hardened Military Bunkers"

        if tags.get('location') == 'underground':
            if tags.get('amenity') == 'parking':
                return "Hardened Infrastructure (dual-use)"
            if tags.get('deep') == 'yes' or tags.get('depth', 0):
                return "Deep Underground Shelters"
            return "Basement / Sub-grade Civilian Shelters"

        if tags.get('amenity') == 'shelter':
            if tags.get('shelter_type') == 'bomb_shelter':
                return "Purpose-Built Public Blast Shelters"
            if tags.get('building') == 'yes':
                return "Improvised / Expedient Shelters"

        # Default fallback
        return "Improvised / Expedient Shelters"

    def _generate_scores(self, shelter_type, tags):
        # Make up some scores (1-10) based on the type we found.
        # Base scores by type (heuristic)
        base_scores = {
            "Basement / Sub-grade Civilian Shelters": 5,
            "Purpose-Built Public Blast Shelters": 8,
            "Hardened Military Bunkers": 10,
            "Deep Underground Shelters": 9,
            "Improvised / Expedient Shelters": 3,
            "Mobile / Deployable Shelters": 4,
            "Hardened Infrastructure (dual-use)": 7
        }

        base = base_scores.get(shelter_type, 5)

        # Add some randomness and tag-based adjustments for demo
        scores = {
            "Protection Score": min(10, max(1, base + random.randint(-1, 1))),
            "Infrastructure Score": min(10, max(1, base + random.randint(-2, 2))),
            "Accessibility Score": random.randint(3, 10),  # Highly variable
            "Capacity Score": random.randint(4, 9),
            "Reliability Score": min(10, max(1, base + random.randint(-1, 2)))
        }

        return scores

    def filter_shelters(self, df, max_distance=None, shelter_type=None):
        # Filter shelters based on max distance or type.
        if df.empty:
            return df

        if max_distance:
            df = df[df['distance_m'] <= max_distance]

        if shelter_type:
            df = df[df['type'] == shelter_type]

        return df


class Storage:
    def __init__(self, data_dir="data"):
        self.data_dir = data_dir
        self.ratings_file = os.path.join(self.data_dir, "ratings.json")
        os.makedirs(self.data_dir, exist_ok=True)

        if not os.path.exists(self.ratings_file):
            self._save_ratings([])

    def _load_ratings(self):
        try:
            with open(self.ratings_file, 'r') as f:
                return json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            return []

    def _save_ratings(self, ratings):
        with open(self.ratings_file, 'w') as f:
            json.dump(ratings, f, indent=2)

    def add_rating(self, shelter_id, rating, comment=""):
        ratings = self._load_ratings()
        ratings.append({
            "shelter_id": shelter_id,
            "rating": rating,
            "comment": comment
        })
        self._save_ratings(ratings)

    def get_ratings_df(self):
        ratings = self._load_ratings()
        if not ratings:
            return pd.DataFrame(columns=["shelter_id", "rating", "comment"])
        return pd.DataFrame(ratings)





# ==========================================
# Machine Learning
# ==========================================

# Constants for ML
ALERTS_API_BASE_URL = "https://api.alerts.in.ua/v1"
ALERTS_API_TOKEN = "3b9da58a53b958cab81355b22e3feb9c10593dc4ab2203"
# All Ukraine region UIDs (official alerts.in.ua list)
ALL_UKRAINE_REGION_UIDS = [
    3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15,
    16, 17, 18, 19, 20, 21, 22, 23, 24,
    25, 26, 27, 28, 29, 30, 31
]


@st.cache_data(ttl=3600)
def load_historical_alerts_for_ml() -> (pd.DataFrame, list):
    # 1. Fetch Data
    headers = {"Authorization": f"Bearer {ALERTS_API_TOKEN}"}
    all_alerts = []
    error_log = []
    region_uids = ALL_UKRAINE_REGION_UIDS

    for uid in region_uids:
        try:
            url = f"{ALERTS_API_BASE_URL}/regions/{uid}/alerts/month_ago.json"
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                data = response.json()
                alerts = data.get("alerts", [])
                for alert in alerts:
                    started_at = pd.to_datetime(alert["started_at"])
                    reg = alert.get("location_title") or alert.get("location_oblast")
                    all_alerts.append({
                        "timestamp": started_at,
                        "region": reg,
                        "month": started_at.month,
                        "day_of_week": started_at.dayofweek,
                        "hour": started_at.hour
                    })
            else:
                error_log.append(f"Failed to fetch data for region {uid}: {response.status_code}")
        except Exception as e:
            error_log.append(f"Error fetching region {uid}: {e}")

    if not all_alerts:
        return pd.DataFrame(), error_log

    df = pd.DataFrame(all_alerts)

    # 2. Create Time Grid (Generate 0s and 1s)
    # We need to create 'safe' (0) hours to train the model properly
    end_date = pd.Timestamp.now(tz='UTC').floor('H')
    start_date = end_date - pd.Timedelta(days=30)
    date_range = pd.date_range(start=start_date, end=end_date, freq='H')

    grid_data = []
    regions = df['region'].unique()

    for region in regions:
        for dt in date_range:
            grid_data.append({
                "timestamp": dt,
                "region": region,
                "month": dt.month,
                "day_of_week": dt.dayofweek,
                "hour": dt.hour
            })

    grid_df = pd.DataFrame(grid_data)

    # 3. Calculate "alert_occurrence"
    # Identify which slots in the grid actually had an alert
    active_slots = set(zip(df['month'], df['day_of_week'], df['hour'], df['region']))

    def is_active(row):
        return 1 if (row['month'], row['day_of_week'], row['hour'], row['region']) in active_slots else 0

    grid_df['alert_occurrence'] = grid_df.apply(is_active, axis=1)

    return grid_df, error_log
    # Feature engineering
    df["month"] = df["timestamp"].dt.month
    df["day"] = df["timestamp"].dt.day
    df["hour"] = df["timestamp"].dt.hour

    # Build full hourly grid (last 30 days)
    end_date = pd.Timestamp.now(tz="UTC").floor("H")
    start_date = end_date - pd.Timedelta(days=30)
    date_range = pd.date_range(start=start_date, end=end_date, freq="H")

    grid_data = []
    regions = df["region"].unique()

    for region in regions:
        for dt in date_range:
            grid_data.append({
                "timestamp": dt,
                "region": region,
                "month": dt.month,
                "day": dt.day,
                "hour": dt.hour,
            })

    grid_df = pd.DataFrame(grid_data)

    # Mark alert hours
    active_slots = set(zip(df["month"], df["day"], df["hour"], df["region"]))
    grid_df["alert_occurrence"] = grid_df.apply(
        lambda r: int((r["month"], r["day"], r["hour"], r["region"]) in active_slots),
        axis=1
    )

    return grid_df


    df = pd.DataFrame(all_alerts)

    # Feature Engineering
    df["month"] = df["timestamp"].dt.month
    df["day_of_week"] = df["timestamp"].dt.dayofweek
    df["hour"] = df["timestamp"].dt.hour

    # Build binary target column alert_occurrence
    # Group by time slots and region to see if an alert existed
    # We want to know: for a given (month, day, hour), was there an alert?
    # Since we only have alert events, we need to be careful.
    # The current approach only has positive samples.
    # To do this properly for a classifier, we usually need negative samples (times with no alerts).
    # However, the prompt asks to "Group data by ... If there is at least one alert in that slot, alert_occurrence = 1, else 0."
    # This implies we might need to generate a grid of all possible hours?
    # Or just aggregate the existing alert data?
    # "Return a clean, deduplicated DataFrame with: month, day_of_week, hour, region, alert_occurrence"
    # If we only use the fetched alerts, we only have 1s.
    # BUT, the prompt says: "Use real historical data... (not simulated data)".
    # And "If there is at least one alert in that slot, alert_occurrence = 1, else 0."
    # If I only have the alerts, I don't have the 0s.
    # I will implement a simplified version that assumes we are characterizing the *alerts*
    # OR I should generate a time range and merge.
    # Given the constraints and the prompt's specific instruction on "Group data by...",
    # I will assume the user wants me to aggregate the *alert* data.
    # BUT, to train a classifier, we definitely need 0s.
    # I will generate a time grid for the last month to create negative samples.

    # Generate full time range for the last 30 days
    end_date = pd.Timestamp.now(tz='UTC').floor('H')
    start_date = end_date - pd.Timedelta(days=30)
    date_range = pd.date_range(start=start_date, end=end_date, freq='H')

    # Create a grid for each region
    grid_data = []
    regions = df['region'].unique()

    for region in regions:
        for dt in date_range:
            grid_data.append({
                "timestamp": dt,
                "region": region,
                "month": dt.month,
                "day_of_week": dt.dayofweek,
                "hour": dt.hour
            })

    grid_df = pd.DataFrame(grid_data)

    # Mark alerts
    # We need to check if an alert was active during that hour.
    # The API gives 'started_at' and 'finished_at'.
    # The prompt says "For each alert entry, create rows... timestamp: parsed from started_at".
    # And "Group data by... If there is at least one alert in that slot...".
    # This suggests we are binning the *start times*?
    # "If there is at least one alert in that slot" (meaning an alert started in that hour?)
    # I will follow the prompt literally: "Group data by ["month", "day_of_week", "hour", "region"]... If there is at least one alert in that slot, alert_occurrence = 1".
    # This implies we are looking at the *presence* of an alert record in that bin.
    # So I will stick to the prompt's implied logic:
    # 1. We have a list of alerts with timestamps.
    # 2. We group them.
    # 3. But we still need 0s.
    # I will stick to the grid approach to ensure we have 0s, otherwise the model is useless.

    # Simplified approach to match prompt "Group data by..." likely implies we take the alerts,
    # and maybe the user assumes we have non-alert data?
    # "Return a clean, deduplicated DataFrame... alert_occurrence (int, 0 or 1)"
    # I will generate the grid to be safe and robust.

    # Mark 1s where we have alerts
    # We'll match on (month, day, hour, region)

    # Create a set of active slots from the alerts
    active_slots = set(zip(df['month'], df['day_of_week'], df['hour'], df['region']))

    def is_active(row):
        return 1 if (row['month'], row['day_of_week'], row['hour'], row['region']) in active_slots else 0

    grid_df['alert_occurrence'] = grid_df.apply(is_active, axis=1)

    return grid_df


@st.cache_resource(show_spinner=True)

def train_alert_risk_model(alerts_df: pd.DataFrame):
    # Teach the model to guess if an alert is coming based on the date and time.
    if alerts_df.empty or "alert_occurrence" not in alerts_df.columns:
        raise ValueError("Input DataFrame is empty or missing required columns.")

    feature_cols = ["month", "day_of_week", "hour", "region_encoded"]
    
    # Encode region
    le = LabelEncoder()
    alerts_df["region_encoded"] = le.fit_transform(alerts_df["region"])
    
    X = alerts_df[feature_cols].values
    y = alerts_df["alert_occurrence"].values

    # Check if we have both classes
    if len(np.unique(y)) < 2:
        # Fallback if only one class (e.g. only 0s or only 1s)
        # This can happen if data is sparse or API fails to give alerts
        st.warning("Not enough data diversity to train model (only one class present).")
        return None, float("nan"), None

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    model = GradientBoostingClassifier(
        n_estimators=200,
        learning_rate=0.05,
        max_depth=3,
        random_state=42
    )
    model.fit(X_train, y_train)

    roc_auc = float("nan")
    if len(np.unique(y_test)) > 1:
        y_proba = model.predict_proba(X_test)[:, 1]
        roc_auc = roc_auc_score(y_test, y_proba)

    return model, roc_auc, le



def predict_alert_probability(model, le, region: str, month: int, day_of_week: int, hour: int) -> float:
    # Ask the trained model how likely an alert is right now for a specific region.
    if not (1 <= month <= 12):
        raise ValueError("Month must be between 1 and 12")
    if not (0 <= day_of_week <= 6):
        raise ValueError("Day of Week must be between 0 (Mon) and 6 (Sun)")
    if not (0 <= hour <= 23):
        raise ValueError("Hour must be between 0 and 23")

    if model is None or le is None:
        return 0.0

    # Encode the region
    try:
        # Note: le.transform expects a list-like input
        region_encoded = le.transform([region])[0]
    except ValueError:
        # Fallback if region was not seen during training
        return 0.0

    X_new = np.array([[month, day_of_week, hour, region_encoded]], dtype=float)
    return model.predict_proba(X_new)[0, 1]

def render_risk_prediction_tab():
    st.header("Air Alert Risk Model")

    # 1) Load data
    with st.spinner("Loading historical alerts..."):
        alerts_df, errors = load_historical_alerts_for_ml()

    # Show errors only if clicked
    if errors:
        with st.expander("View Data Loading Errors"):
            for err in errors:
                st.error(err)

    if alerts_df.empty:
        st.error("No alert data loaded. Cannot train model.")
    else:
        st.success(f"Loaded {len(alerts_df)} rows of alert data.")

        # 2) Train model
        with st.spinner("Training alert risk model (Region-Aware)..."):
            model, roc_auc, le = train_alert_risk_model(alerts_df)

        if model is None:
            st.warning("Model could not be trained (only one class present).")
        else:
            st.write(f"Model ROC AUC: {roc_auc:.3f}")

            # 3) User inputs for prediction
            st.subheader("Predict alert probability")

            # Get unique regions for dropdown, sorted
            available_regions = sorted(alerts_df["region"].unique().tolist())

            col1, col2 = st.columns(2)
            with col1:
                selected_region = st.selectbox("Region", available_regions)
            
            col_a, col_b, col_c = st.columns(3)
            with col_a:
                month = st.number_input("Month (1‚Äì12)", min_value=1, max_value=12, value=1)
            with col_b:
                # User wants "Day of Week" (Mon, Tue...) in UI? 
                # "Switch 'Day of Month' (e.g., 1st, 2nd, 3rd) back to 'Day of Week' (Mon, Tue, Wed, etc)"
                # I should probably map names to 0-6 integers.
                days_map = {
                    "Monday": 0, "Tuesday": 1, "Wednesday": 2, "Thursday": 3, 
                    "Friday": 4, "Saturday": 5, "Sunday": 6
                }
                day_name = st.selectbox("Day of Week", list(days_map.keys()))
                day_of_week = days_map[day_name]
            with col_c:
                hour = st.number_input("Hour (0‚Äì23)", min_value=0, max_value=23, value=12)

            if st.button("Predict"):
                prob = predict_alert_probability(model, le, selected_region, month, day_of_week, hour)
                st.metric(f"Risk for {selected_region}", f"{prob:.1%}")

class SafetyModel:
    def __init__(self):
        # Placeholder for a real model ‚Äì you can later plug in ML here if you want
        pass

    def predict_safety_score(self, distance_m, is_alert_active, protection_score=5):
        # Guess how safe you are (0-100) based on distance and shelter quality.
        # Simple heuristic: closer & better-protected shelters are safer
        base_score = 100 - (distance_m / 50)  # lose 1 point every 50 m

        # Bonus for good protection
        base_score += (protection_score - 5) * 2

        if is_alert_active:
            base_score -= 20

        # Clamp between 0 and 100
        return max(0, min(100, base_score))

    def predict_time_to_danger(self, region_id):
        # Guess how long until things get dangerous (minutes).
        # Random prediction for demo purposes
        return random.randint(5, 30)

class ReliabilityModel:
    def calculate_reliability(self, ratings_df, shelter_id):
        # Figure out if a shelter is reliable based on user votes.
        # We use a math trick (Bayesian average) so one bad vote doesn't ruin a new shelter.
        if ratings_df.empty:
            return 5.0  # Default neutral score

        shelter_ratings = ratings_df[ratings_df['shelter_id'] == shelter_id]

        if shelter_ratings.empty:
            return 5.0

        # Bayesian Average
        # C = global average rating
        # m = minimum votes required to be listed (smoothing factor)
        C = ratings_df['rating'].mean()
        m = 2

        v = len(shelter_ratings)
        R = shelter_ratings['rating'].mean()

        weighted_rating = (v / (v + m)) * R + (m / (v + m)) * C
        return round(weighted_rating, 2)

    def analyze_sentiment(self, comment):
        # Determine if a comment is positive or negative.
        positive_keywords = ['safe', 'clean', 'good', 'spacious', 'accessible']
        negative_keywords = ['dirty', 'crowded', 'closed', 'locked', 'unsafe']

        score = 0
        lower_comment = comment.lower()

        for word in positive_keywords:
            if word in lower_comment:
                score += 1

        for word in negative_keywords:
            if word in lower_comment:
                score -= 1

        return score

# ==========================================
# UI Components
# ==========================================

class MapComponent:
    def render(self, user_lat, user_lon, shelters_df, route_geojson=None):
        # Draw the map with the user, the shelters, and the path (if we have one).
        # We return the map so we can tell where the user clicked.
        # Create base map
        m = folium.Map(location=[user_lat, user_lon], zoom_start=14)

        # User Marker
        folium.Marker(
            [user_lat, user_lon],
            popup="You are here",
            tooltip="Your Location",
            icon=folium.Icon(color="blue", icon="user")
        ).add_to(m)

        # Shelters
        if not shelters_df.empty:
            def get_color(type_name):
                colors = {
                    "Basement / Sub-grade Civilian Shelters": "orange",
                    "Purpose-Built Public Blast Shelters": "green",
                    "Hardened Military Bunkers": "black",
                    "Deep Underground Shelters": "darkgreen",
                    "Improvised / Expedient Shelters": "red",
                    "Mobile / Deployable Shelters": "beige",
                    "Hardened Infrastructure (dual-use)": "blue"
                }
                return colors.get(type_name, "gray")

            for _, row in shelters_df.iterrows():
                color = get_color(row['type'])

                popup_html = f"""
                <b>{row['name']}</b><br>
                Type: {row['type']}<br>
                Protection: {row.get('Protection Score', 'N/A')}/10<br>
                Reliability: {row.get('Reliability Score', 'N/A')}/10
                """

                folium.CircleMarker(
                    location=[row['lat'], row['lon']],
                    radius=8,
                    popup=folium.Popup(popup_html, max_width=300),
                    tooltip=f"{row['name']} ({row['type']})",
                    color=color,
                    fill=True,
                    fill_color=color
                ).add_to(m)

        # Route
        if route_geojson:
            folium.GeoJson(
                route_geojson,
                name="Route",
                style_function=lambda x: {'color': 'red', 'weight': 5, 'opacity': 0.7}
            ).add_to(m)

        # Return the map object to be rendered by st_folium
        # We want to capture clicks on the map
        return st_folium(m, width=None, height=500, returned_objects=["last_clicked"])


class Dashboard:
    def render_status_panel(self, alerts_data):
        active_alerts = [a for a in alerts_data.get('alerts', []) if a['alert_type'] == 'air_raid']
        count = len(active_alerts)

        if count > 0:
            st.error(f"üö® AIR RAID ALERT ACTIVE! ({count} regions)")
            with st.expander("View Affected Regions"):
                for alert in active_alerts:
                    st.warning(f"üìç {alert['location_title']} (since {alert['started_at']})")
        else:
            st.success("‚úÖ No Active Air Raid Alerts")

    def render_metrics(self, nearest_shelter, safety_score, time_to_danger):
        cols = st.columns(3)
        with cols[0]:
            if not nearest_shelter.empty:
                st.metric("Nearest Shelter", f"{int(nearest_shelter['distance_m'])} m", nearest_shelter['name'])
            else:
                st.metric("Nearest Shelter", "N/A")

        with cols[1]:
            delta_color = "normal"
            if safety_score > 80:
                delta_color = "normal"  # Greenish usually
            elif safety_score < 50:
                delta_color = "inverse"

            st.metric("Current Safety Score", f"{int(safety_score)}/100", delta_color=delta_color)

        with cols[2]:
            st.metric("Est. Time to Danger", f"{time_to_danger} min")

    def render_shelter_scores(self, shelter_row):
        # Show specific scores for the shelter (Protection, Capacity, etc.)
        if shelter_row.empty:
            return

        st.subheader("üìä Shelter Quality Ratings")
        st.info("‚ÑπÔ∏è Note: These scores are heuristic estimates based on shelter type and available metadata, not real-time verified conditions.")

        score_cols = [
            "Protection Score",
            "Infrastructure Score",
            "Accessibility Score",
            "Capacity Score",
            "Reliability Score"
        ]

        # Use columns to display small progress bars or metrics
        cols = st.columns(len(score_cols))
        
        for idx, col in enumerate(cols):
            score_name = score_cols[idx]
            val = shelter_row.get(score_name, 0)
            with col:
                st.write(f"**{score_name.replace(' Score', '')}**")
                st.progress(int(val) / 10)
                st.caption(f"{val}/10")


class Sidebar:
    def __init__(self, geolocator):
        self.geolocator = geolocator
        self.cities = {
            "Kyiv": {"lat": 50.4501, "lon": 30.5234},
            "Kharkiv": {"lat": 49.9935, "lon": 36.2304},
            "Odesa": {"lat": 46.4825, "lon": 30.7233},
            "Dnipro": {"lat": 48.4647, "lon": 35.0462},
            "Donetsk": {"lat": 48.0159, "lon": 37.8028},
            "Zaporizhzhia": {"lat": 47.8388, "lon": 35.1396},
            "Lviv": {"lat": 49.8397, "lon": 24.0297},
            "Kryvyi Rih": {"lat": 47.9105, "lon": 33.3918},
            "Mykolaiv": {"lat": 46.9750, "lon": 31.9946},
            "Mariupol": {"lat": 47.0971, "lon": 37.5434},
            "Luhansk": {"lat": 48.5740, "lon": 39.3078},
            "Vinnytsia": {"lat": 49.2331, "lon": 28.4682},
            "Simferopol": {"lat": 44.9572, "lon": 34.1108},
            "Chernihiv": {"lat": 51.4982, "lon": 31.2893},
            "Kherson": {"lat": 46.6354, "lon": 32.6169},
            "Poltava": {"lat": 49.5883, "lon": 34.5514},
            "Khmelnytskyi": {"lat": 49.4230, "lon": 26.9871},
            "Cherkasy": {"lat": 49.4444, "lon": 32.0598},
            "Chernivtsi": {"lat": 48.2921, "lon": 25.9352},
            "Zhytomyr": {"lat": 50.2547, "lon": 28.6587},
            "Sumy": {"lat": 50.9077, "lon": 34.7981},
            "Rivne": {"lat": 50.6199, "lon": 26.2516},
            "Ivano-Frankivsk": {"lat": 48.9226, "lon": 24.7111},
            "Ternopil": {"lat": 49.5535, "lon": 25.5948},
            "Lutsk": {"lat": 50.7472, "lon": 25.3254},
            "Uzhhorod": {"lat": 48.6208, "lon": 22.2879}
        }

    def render(self):
        st.sidebar.header("Settings")
        st.sidebar.subheader("Your Location")
        
        input_method = st.sidebar.radio(
            "Input Method",
            ["City Selection", "Address Search", "Manual Coordinates"] 
        )

        if 'user_lat' not in st.session_state:
            st.session_state.user_lat = 50.4501
        if 'user_lon' not in st.session_state:
            st.session_state.user_lon = 30.5234

        lat, lon = st.session_state.user_lat, st.session_state.user_lon

        if input_method == "City Selection":
            sorted_cities = sorted(list(self.cities.keys()))
            default_index = sorted_cities.index("Kyiv") if "Kyiv" in sorted_cities else 0
            
            city_name = st.sidebar.selectbox("Select City", sorted_cities, index=default_index)
            coords = self.cities[city_name]
            lat, lon = coords['lat'], coords['lon']
            st.session_state.user_lat = lat
            st.session_state.user_lon = lon

        elif input_method == "Address Search":
            address = st.sidebar.text_input("Enter Address (e.g. 'Maidan Nezalezhnosti, Kyiv')")
            if st.sidebar.button("üîç Search Address"):
                if address:
                    with st.spinner("Searching map..."):
                        try:
                            location = self.geolocator.geocode(address)
                            if location:
                                lat = location.latitude
                                lon = location.longitude
                                st.session_state.user_lat = lat
                                st.session_state.user_lon = lon
                                st.sidebar.success(f"üìç Found: {location.address}")
                            else:
                                st.sidebar.error("‚ùå Address not found. Try adding the city name.")
                        except Exception as e:
                            st.sidebar.error(f"Error: {e}")

        elif input_method == "Manual Coordinates":
            lat = st.sidebar.number_input("Latitude", value=st.session_state.user_lat, format="%.4f")
            lon = st.sidebar.number_input("Longitude", value=st.session_state.user_lon, format="%.4f")
            st.session_state.user_lat = lat
            st.session_state.user_lon = lon


        st.sidebar.markdown("---")
        max_dist = st.sidebar.slider("Max Search Distance (m)", 500, 5000, 1000)
        
        # --- ROUTING ---
        st.sidebar.subheader("Routing Options")
        mode_choice = st.sidebar.radio(
            "Choose Travel Mode:",
            ["Walking üö∂", "Driving üöó"],
            index=0
        )
        travel_mode = "foot-walking" if "Walking" in mode_choice else "driving-car"

        return {
            "lat": lat,
            "lon": lon,
            "selected_type": "All", # Hardcoded 'All' since button is gone
            "max_dist": max_dist,
            "input_method": input_method,
            "travel_mode": travel_mode 
        }
# ==========================================
# Main Application
# ==========================================

def main():
    st.set_page_config(page_title="SecurityUA", layout="wide")
    st.title("üõ°Ô∏è SecurityUA ‚Äì Ukraine Air Alerts Monitor")

    # Sidebar (global settings)
    st.sidebar.header("Settings")
    refresh_interval = st.sidebar.slider("Auto-refresh (sec)", 10, 300, 60)
    auto_refresh = st.sidebar.checkbox("Enable auto-refresh", value=True)

    # Initialize clients / helpers
    alerts_client = AlertsClient()
    routing_client = RoutingClient() 
    processor = DataProcessor()
    safety_model = SafetyModel()
    map_component = MapComponent()
    dashboard = Dashboard()
    
    geolocator = Nominatim(user_agent="security_ua_tracker")
    sidebar = Sidebar(geolocator)

    # Create Tabs
    tab1, tab2 = st.tabs(["Monitor", "Risk Prediction"])

    # =======================
    # TAB 1: LIVE MONITORING
    # =======================
    with tab1:
        # --- Alerts + Region Notification ---
        try:
            alerts_data = alerts_client.get_active_alerts()
        except Exception:
            alerts_data = {}

        watched_region = None  # store the user-selected region

        if alerts_data:
            df_alerts = build_alerts_dataframe(alerts_data)
            if not df_alerts.empty:
                # Sidebar selectbox: which region should trigger notifications?
                region_names = sorted(df_alerts["location_title"].dropna().unique())
                if region_names:
                    watched_region = st.sidebar.selectbox(
                        "üîî Notify me about alerts in:",
                        options=region_names,
                        index=region_names.index("Kyiv Oblast") if "Kyiv Oblast" in region_names else 0
                    )

                # Existing table of active alerts
                with st.expander("üö® Active Alerts", expanded=False):
                    st.dataframe(df_alerts, use_container_width=True)

        # --- Real-Time Region-Specific Alert Notifications (UI toast + optional alarm) ---
        if "last_region_alert_active" not in st.session_state:
            st.session_state.last_region_alert_active = False

        region_alert_active = False
        if alerts_data and watched_region:
            region_alert_active = is_region_under_air_raid(alerts_data, watched_region)

        # Fire notification only when state changes: False -> True
        if region_alert_active and not st.session_state.last_region_alert_active:
            # Visual toast in the app
            st.toast(f"üö® NEW AIR ALERT in {watched_region}!", icon="‚ö†Ô∏è")

            # Optional: small alarm sound (tab must be opened/allowed to play audio)
            st.markdown(
                """
                <audio autoplay>
                    <source src="https://actions.google.com/sounds/v1/alarms/alarm_clock.ogg" type="audio/ogg">
                </audio>
                """,
                unsafe_allow_html=True,
            )

        # Update state for next rerun
        st.session_state.last_region_alert_active = region_alert_active

        # --- Map & Shelter Logic ---
        user_settings = sidebar.render()
        user_lat = user_settings['lat']
        user_lon = user_settings['lon']

        st.markdown("### üó∫Ô∏è Live Shelter Map")

        # Load Data
        with st.spinner("Loading shelters..."):
            try:
                shelters_raw = load_data()
                if isinstance(shelters_raw, pd.DataFrame):
                    shelters_raw = shelters_raw.to_dict('records')
            except Exception:
                shelters_raw = []

        # Process & Filter
        shelters_df = processor.process_shelters(shelters_raw, user_lat, user_lon)

        # Distance Filter
        nearby_df = shelters_df[shelters_df['distance_m'] <= user_settings['max_dist']]
        
        if nearby_df.empty and not shelters_df.empty:
            st.warning(f"‚ö†Ô∏è No shelters found within {user_settings['max_dist']}m. Showing the closest 10.")
            shelters_df = shelters_df.head(10)
        else:
            shelters_df = nearby_df

        # Routing Logic
        nearest_shelter = pd.Series()
        route_geojson = None
        safety_score = 0
        time_to_danger = safety_model.predict_time_to_danger("Kyiv")
        is_alert_active = False  # you could also wire this to alerts_data if you want

        if not shelters_df.empty:
            # Funnel (Top 5)
            candidates = shelters_df.head(5).copy()

            # Matrix API
            with st.spinner("Calculating optimal route..."):
                nearest_shelter = routing_client.find_quickest_shelter(
                    user_lon, user_lat, candidates, profile=user_settings['travel_mode']
                )

            # Route Line
            route_geojson = routing_client.get_route(
                (user_lon, user_lat),
                (nearest_shelter['lon'], nearest_shelter['lat']),
                profile=user_settings['travel_mode']
            )
            
            # Scoring
            protection = nearest_shelter.get('Protection Score', 5)
            safety_score = safety_model.predict_safety_score(
                nearest_shelter['distance_m'], is_alert_active, protection
            )

        # Render Metrics
        if 'duration_s' in nearest_shelter:
            import math
            mins = math.ceil(nearest_shelter['duration_s'] / 60)
            mode = "Walking" if user_settings['travel_mode'] == 'foot-walking' else "Driving"
            
            c1, c2, c3 = st.columns(3)
            time_display = f"{mins} min" if mins > 0 else "< 1 min"
            c1.metric(f"Time to Shelter ({mode})", time_display, nearest_shelter['name'])
            
            delta_color = "normal"
            if safety_score > 80:
                delta_color = "normal"
            elif safety_score < 50:
                delta_color = "inverse"
            c2.metric("Safety Score", f"{int(safety_score)}/100", delta_color=delta_color)
            
            c3.metric("Est. Danger In", f"{time_to_danger} min")
        else:
            dashboard.render_metrics(nearest_shelter, safety_score, time_to_danger)

        # Render Shelter Scores
        if not nearest_shelter.empty:
            st.markdown("---")
            dashboard.render_shelter_scores(nearest_shelter)

        # Render Map
        map_data = map_component.render(user_lat, user_lon, shelters_df, route_geojson)

        # Map Click: allow user to move their "You are here" marker by clicking
        if map_data and map_data.get("last_clicked"):
            lat = map_data["last_clicked"]["lat"]
            lng = map_data["last_clicked"]["lng"]
            if lat != st.session_state.user_lat or lng != st.session_state.user_lon:
                st.session_state.user_lat = lat
                st.session_state.user_lon = lng
                st.rerun()

    # =======================
    # TAB 2: RISK PREDICTION
    # =======================
    with tab2:
        render_risk_prediction_tab()

    # Global auto-refresh for the whole app
    if auto_refresh:
        time.sleep(refresh_interval)
        st.rerun()


if __name__ == "__main__":
    main()
